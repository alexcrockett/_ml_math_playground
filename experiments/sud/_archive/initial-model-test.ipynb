{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For kicks, we're going to build a super simple neural network with only one layer.\n",
    "\n",
    "- Import libraries and data\n",
    "- Identify stocks we want to highlight\n",
    "- These will be stocks that increase in value the next day\n",
    "- So 'high' higher than previous 'high'\n",
    "- Create a matrix of our training values\n",
    "- Define our parameters matrix\n",
    "- Pass data the data through activation function\n",
    "- Pass to Loss function\n",
    "- Back propagation"
   ],
   "id": "b876abaf531f5813"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T21:34:06.688097Z",
     "start_time": "2024-12-02T21:34:06.674979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First we import libraries and build arrays and tensors\n",
    "import pandas as pd  # To manage the initial dataframe\n",
    "import numpy as np  # Prec-process and organize the data\n",
    "import tensorflow as tf  # Build tensors\n",
    "import tensorflow.keras as keras  # Compute the activation\n",
    "\n",
    "data_file = pd.read_csv('C:/Users/alexa/Documents/Code/Jupyter Playground/Apple Stocks/02-data/AppleStockPrices.csv')\n",
    "\n",
    "data_file.head()"
   ],
   "id": "ec2ae4636db845c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Date    Open    High     Low   Close    Volume  Adj Close\n",
       "0  1/3/2011  325.64  330.26  324.84  329.57  15883600     329.57\n",
       "1  1/4/2011  332.44  332.50  328.15  331.29  11038600     331.29\n",
       "2  1/5/2011  329.55  334.34  329.50  334.00   9058700     334.00\n",
       "3  1/6/2011  334.72  335.25  332.90  333.73  10709500     333.73\n",
       "4  1/7/2011  333.99  336.35  331.90  336.12  11096800     336.12"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2011</td>\n",
       "      <td>325.64</td>\n",
       "      <td>330.26</td>\n",
       "      <td>324.84</td>\n",
       "      <td>329.57</td>\n",
       "      <td>15883600</td>\n",
       "      <td>329.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2011</td>\n",
       "      <td>332.44</td>\n",
       "      <td>332.50</td>\n",
       "      <td>328.15</td>\n",
       "      <td>331.29</td>\n",
       "      <td>11038600</td>\n",
       "      <td>331.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2011</td>\n",
       "      <td>329.55</td>\n",
       "      <td>334.34</td>\n",
       "      <td>329.50</td>\n",
       "      <td>334.00</td>\n",
       "      <td>9058700</td>\n",
       "      <td>334.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2011</td>\n",
       "      <td>334.72</td>\n",
       "      <td>335.25</td>\n",
       "      <td>332.90</td>\n",
       "      <td>333.73</td>\n",
       "      <td>10709500</td>\n",
       "      <td>333.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/7/2011</td>\n",
       "      <td>333.99</td>\n",
       "      <td>336.35</td>\n",
       "      <td>331.90</td>\n",
       "      <td>336.12</td>\n",
       "      <td>11096800</td>\n",
       "      <td>336.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 382
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- We don't care about Date or Adj Close\n",
    "- We will seperate out all those values where the next day is higher\n",
    "- We will then have one set whose value after applying the sigmoid is 1\n",
    "- We will also have another set whose value after applying the sigmoid is 0"
   ],
   "id": "371480e74319a95c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T21:34:06.749328Z",
     "start_time": "2024-12-02T21:34:06.739777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Here we build out the arrays and data structures that we need\n",
    "\n",
    "# Identify the data we care about\n",
    "wip_data = data_file[['Open', 'High', 'Low', 'Close', 'Volume']]  # The values we will use for the model\n",
    "\n",
    "# Build our labeled df\n",
    "High_stop = wip_data['High']  # Value we are testing against\n",
    "High_start = wip_data['High'].shift(periods=1)  # Starting value to be subtracted\n",
    "\n",
    "# Create a matrix with high subtracted from next days high\n",
    "labeled_df = High_stop - High_start  # Values we will label\n",
    "\n",
    "# We can then convert everything to numpy arrays to work with\n",
    "ml_data = wip_data.to_numpy()  # Our primary data to numpy\n",
    "ml_labels_wip = labeled_df.to_numpy()  # Our labels to numpy\n",
    "ml_labels = np.empty(34, dtype=float)  # An empty array for our final labeling\n",
    "\n",
    "# Convert the labels array into 0 and 1 labels\n",
    "ml_labels[ml_labels_wip < 1] = 0   # Label values losing value\n",
    "ml_labels[ml_labels_wip >= 1] = 1   # Label values gaining value\n",
    "\n",
    "# Now we will build the data to train on\n",
    "x_data_product = np.prod(ml_data, axis=1)  # Multiply rows in the main array so we have a single vector\n",
    "\n",
    "# Normalize the multiplied data (min-max normalization)\n",
    "min_val = np.min(x_data_product)  # Identify the smallest value\n",
    "max_val = np.max(x_data_product)  # Identify the largest value\n",
    "x = (x_data_product - min_val) / (max_val - min_val)  # Calculate the final normalized value\n",
    "\n",
    "# Create the weights of our array\n",
    "w = np.random.randn(len(x))  # Create a randomized set of weights for training\n",
    "\n",
    "# Weighted array\n",
    "ml_xw = x * w  # Multiply input values by weights (note that we're doing a row by row operation and not the dot product\n",
    "\n",
    "print(ml_labels.shape)\n",
    "print(ml_xw.shape)"
   ],
   "id": "a33f39095b3043da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34,)\n",
      "(34,)\n"
     ]
    }
   ],
   "execution_count": 383
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T21:34:06.845865Z",
     "start_time": "2024-12-02T21:34:06.838518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We're going to use the tanh function as our activation function\n",
    "# We will use keras to do this as it does a lot of the work for us\n",
    "\n",
    "# Convert our arrays to tensors\n",
    "k_xw = tf.convert_to_tensor(ml_xw)\n",
    "y = tf.convert_to_tensor(ml_labels)\n",
    "\n",
    "# Run the activation function (Hyperbolic Tanh)\n",
    "y_hat_init = keras.activations.tanh(k_xw)\n",
    "\n",
    "# We're going to use binary cross entropy for our loss function so need to adjust our initial output\n",
    "y_hat = (y_hat_init + 1) / 2.0\n",
    "print(y_hat.shape)\n",
    "print(y.shape)"
   ],
   "id": "b67f598025de21f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34,)\n",
      "(34,)\n"
     ]
    }
   ],
   "execution_count": 384
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T21:34:06.899621Z",
     "start_time": "2024-12-02T21:34:06.894822Z"
    }
   },
   "cell_type": "code",
   "source": "y",
   "id": "cda616d88362c137",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(34,), dtype=float64, numpy=\n",
       "array([nan,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,\n",
       "        0.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
       "        1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.])>"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 385
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T21:34:06.947624Z",
     "start_time": "2024-12-02T21:34:06.941706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Binary cross entropy is defined as-(y\\cdot{log}(p_i)+(1-y_i)\\cdot{log}(1-p_i))\n",
    "# We will do the operation manually in np\n",
    "\n",
    "# Convert tensors to arrays\n",
    "y_hat_np = tf.keras.ops.convert_to_numpy(y_hat)  # Convert y_hat to np array\n",
    "y_np = tf.keras.ops.convert_to_numpy(y)  # Convert y to np array\n",
    "\n",
    "# Removing the first value from each to get rid of the NaN value\n",
    "y_np[np.isnan(y_np)] = np.mean(y_np[np.logical_not(np.isnan(y_np))])\n",
    "epsilon = 1e-7\n",
    "y_hat_np = np.clip(y_hat_np, epsilon, 1 - epsilon) \n",
    "\n",
    "print(y_hat_np.shape)\n",
    "print(y_np.shape)\n",
    "\n",
    "bce = -np.mean((y_np * np.log(y_hat_np)) + (1 - y_np) * np.log(1 - y_hat_np))\n",
    "print(bce)"
   ],
   "id": "e1c2b276ff253394",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34,)\n",
      "(34,)\n",
      "0.7186066510319156\n"
     ]
    }
   ],
   "execution_count": 386
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T21:34:06.992401Z",
     "start_time": "2024-12-02T21:34:06.982837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Next step will be to run backpropagation on the network to update the weights \n",
    "\n",
    "# Make sure everything has a mathing shape\n",
    "\n",
    "# Derivative of the loss function\n",
    "loss_grad = (y_hat_np - y_np) / (y_hat_np * (1 - y_hat_np))\n",
    "\n",
    "# Derivative of the activation function \n",
    "activation_grad = 1 - np.tanh(ml_xw) ** 2 \n",
    "\n",
    "# Learning rate \n",
    "learning_rate = 0.001 \n",
    "\n",
    "# Compute the overall gradient for weights \n",
    "overall_grad = loss_grad * activation_grad \n",
    "\n",
    "# Update weights  \n",
    "weights_update = learning_rate * overall_grad * x \n",
    "w -= weights_update \n",
    "\n",
    "print(\"Updated Weights:\", w)"
   ],
   "id": "fc22fc1c19737ba8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Weights: [-0.17075729 -2.2733749  -0.18078474  0.61515213 -0.81707099 -0.38942105\n",
      "  2.41769458  2.45869366 -1.67501045 -0.38708297 -2.27990755 -1.21382289\n",
      "  0.64120267 -1.1558855   1.73577321 -0.44085734 -0.03333584 -0.55049657\n",
      " -1.22485986 -0.04507611 -1.21075773  1.00612847  1.32497119 -0.23640786\n",
      "  1.23762109  0.68091641  0.18921295 -1.04267805  0.76123833 -1.02813454\n",
      "  1.73821841 -0.99437929 -0.97030293 -0.81891997]\n"
     ]
    }
   ],
   "execution_count": 387
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T21:34:07.054792Z",
     "start_time": "2024-12-02T21:34:07.042404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now we will run a couple more epochs to see if the value of our loss decreases\n",
    "weights = w\n",
    "values = w * x\n",
    "actual = y_np\n",
    "actual[0] = 1\n",
    "prediction = np.tanh(values)\n",
    "epsilon = 1e-7  # Small value to avoid log(0)\n",
    "prediction = np.clip(prediction, epsilon, 1 - epsilon)\n",
    "loss_calc = -np.mean(actual * np.log(prediction) + (1 - actual) * np.log(1 - prediction))\n",
    "print(\"Original Loss: \", bce)\n",
    "print(\"Updated Loss: \", loss_calc)\n",
    "\n",
    "loss_grad_2 = (prediction - actual) / (prediction * (1 - prediction))\n",
    "activation_grad_2 = 1 - np.tanh(prediction) ** 2\n",
    "learning_rate_2 = 0.999999  # Updating the learning rate to speed up performance\n",
    "overall_grad_2 = loss_grad_2 * activation_grad_2\n",
    "weights_update_2 = learning_rate_2 * overall_grad_2 * x\n",
    "w -= weights_update_2\n",
    "\n",
    "values = w * x\n",
    "actual = y_np\n",
    "actual[0] = 1\n",
    "prediction = np.tanh(values)\n",
    "epsilon = 1e-7  # Small value to avoid log(0)\n",
    "prediction = np.clip(prediction, epsilon, 1 - epsilon)\n",
    "loss_calc = -np.mean(actual * np.log(prediction) + (1 - actual) * np.log(1 - prediction))\n",
    "print(\"2nd Loss calc: \", loss_calc)\n",
    "\n",
    "loss_grad_2 = (prediction - actual) / (prediction * (1 - prediction))\n",
    "activation_grad_2 = 1 - np.tanh(prediction) ** 2\n",
    "learning_rate_2 = 0.999999  # Updating the learning rate to speed up performance\n",
    "overall_grad_2 = loss_grad_2 * activation_grad_2\n",
    "weights_update_2 = learning_rate_2 * overall_grad_2 * x\n",
    "w -= weights_update_2\n",
    "\n",
    "values_3 = w * x\n",
    "prediction = np.tanh(values_3)\n",
    "epsilon = 1e-7  # Small value to avoid log(0)\n",
    "prediction = np.clip(prediction, epsilon, 1 - epsilon)\n",
    "loss_calc = -np.mean(actual * np.log(prediction) + (1 - actual) * np.log(1 - prediction))\n",
    "print(\"Final loss value: \", loss_calc)"
   ],
   "id": "c051cc99b0a22d1a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Loss:  0.7186066510319156\n",
      "Updated Loss:  7.402623444854449\n",
      "2nd Loss calc:  0.6153725689342333\n",
      "Final loss value:  0.5937316041235796\n"
     ]
    }
   ],
   "execution_count": 388
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c1e267d0b3cc58ea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
