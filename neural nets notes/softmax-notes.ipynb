{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Notes on Softmax\n",
    "\n",
    "#### References\n",
    "- https://en.wikipedia.org/wiki/Softmax_function\n",
    "- https://medium.com/@hunter-j-phillips/a-simple-introduction-to-softmax-287712d69bac\n",
    "- https://www.singlestore.com/blog/a-guide-to-softmax-activation-function/\n",
    "- And from PyTorch https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html\n",
    "\n",
    "#### Notes\n",
    "The softmax function is used for classification purposes in machine learning. Specifically, it is used to classify between 2 or more examples. It works by amplifying larger and minimizing smaller contributions to an array. As such, it follows from the logic of the sigmoid function. \n",
    "\n",
    "The softmax works by assigning probabilities to each value. It does this by normalizing rows so that the row sums to one. The softmax function is given in the following equation:\n",
    "\n",
    "$$\\sigma(\\overrightarrow{z})=\\frac{e^{z-i}}{\\sum^k_{j=1}e^{z_j}}$$\n",
    "\n",
    "Here\n",
    "- $\\overrightarrow{z}$ is the input vector\n",
    "- $K\\ge{1}$, the components of $\\overrightarrow{z}$\n",
    "\n",
    "<br>\n",
    "\n",
    "In other words, each value as the power of the exponential is divided by the sum of the row's values. \n",
    "\n",
    "<br>\n",
    "\n",
    "In practice, this will be achieved in the following way:\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\sigma(\\overrightarrow{z})=\\begin{bmatrix} x_1,\\; x_2,\\; \\dots,\\; x_n\\end{bmatrix}\\;=\\;\\begin{bmatrix}\\frac{e^{x_1}}{\\sum_{j}e^{x_j}},\\; \\frac{e^{x_2}}{\\sum_{j}e^{x_j}},\\; \\dots,\\; \\frac{e^{x_n}}{\\sum_{j}e^{x_j}}  \\end{bmatrix}$\n",
    "\n",
    "<br>\n",
    "\n",
    "Which, extending to an $i*j$ matrix gives is\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "    \\frac{e^{x_{11}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{12}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{13}}}{\\sum_{j}e^{x_{1j}}} & \\dots  & \\frac{e^{x_{1n}}}{\\sum_{j}e^{x_{1j}}} \\\\\n",
    "    \\frac{e^{x_{21}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{22}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{23}}}{\\sum_{j}e^{x_{2j}}} & \\dots  & \\frac{e^{x_{2n}}}{\\sum_{j}e^{x_{2j}}} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\frac{e^{x_{m1}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m2}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m3}}}{\\sum_{j}e^{x_{mj}}} & \\dots  & \\frac{e^{x_{mn}}}{\\sum_{j}e^{x_{mj}}}\n",
    "\\end{bmatrix}$"
   ],
   "id": "40c4c96346e6bcad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:44:33.549076Z",
     "start_time": "2024-11-20T09:44:33.537900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First let's import the libraries and build an array\n",
    "import numpy as np\n",
    "\n",
    "# Build and array\n",
    "array = np.random.randint(low = 0, high = 20, size = (5, 3))\n",
    "print(array)"
   ],
   "id": "53b33dda03d58899",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  5  1]\n",
      " [ 2  7  5]\n",
      " [17 16 13]\n",
      " [ 4 11  8]\n",
      " [16 15 17]]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:47:42.741088Z",
     "start_time": "2024-11-20T09:47:42.722273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now we will compute the softmax\n",
    "exponent_array = np.exp(array)\n",
    "exponential_sum = np.sum(exponent_array, axis = 1, keepdims = True)\n",
    "computed_softmax = exponent_array / exponential_sum\n",
    "print(computed_softmax)"
   ],
   "id": "b4dbb45fa4af4f61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.27475157e-01 2.67623154e-01 4.90168905e-03]\n",
      " [5.89975040e-03 8.75600595e-01 1.18499655e-01]\n",
      " [7.21399184e-01 2.65387929e-01 1.32128870e-02]\n",
      " [8.67881295e-04 9.51747406e-01 4.73847131e-02]\n",
      " [2.44728471e-01 9.00305732e-02 6.65240956e-01]]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:25:47.318809Z",
     "start_time": "2024-11-20T20:25:47.312451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# \n",
    "print(array.shape)\n",
    "print(array.ndim)"
   ],
   "id": "fcc077aad9774a2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3)\n",
      "2\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:48:47.962606Z",
     "start_time": "2024-11-20T20:48:47.954662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import PyTorch to use the PyTorch softmax\n",
    "import torch\n",
    "\n",
    "# Convert the np array to a torch tensor\n",
    "tensor = torch.from_numpy(array).float()\n",
    "\n",
    "# Check the tensor\n",
    "print(tensor)\n",
    "print(tensor.size())\n",
    "print(tensor.dtype)\n",
    "\n",
    "# Run the Softmax operation on the tensor\n",
    "softmax_function = torch.nn.Softmax(dim=1)\n",
    "softmax_operation = softmax_function(tensor)\n",
    "print(softmax_operation)\n"
   ],
   "id": "228131489317e5ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.,  5.,  1.],\n",
      "        [ 2.,  7.,  5.],\n",
      "        [17., 16., 13.],\n",
      "        [ 4., 11.,  8.],\n",
      "        [16., 15., 17.]])\n",
      "torch.Size([5, 3])\n",
      "torch.float32\n",
      "tensor([[7.2748e-01, 2.6762e-01, 4.9017e-03],\n",
      "        [5.8998e-03, 8.7560e-01, 1.1850e-01],\n",
      "        [7.2140e-01, 2.6539e-01, 1.3213e-02],\n",
      "        [8.6788e-04, 9.5175e-01, 4.7385e-02],\n",
      "        [2.4473e-01, 9.0031e-02, 6.6524e-01]])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "87842364bdc2812f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
