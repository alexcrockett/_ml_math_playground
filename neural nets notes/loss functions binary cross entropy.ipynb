{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Notes\n",
    "\n",
    "In this file we're going to explore three loss functions\n",
    "\n",
    "1. Mean Absolute Error\n",
    "2. Mean Squared Error\n",
    "3. Binary Cross Entropy\n",
    "\n",
    "</br>\n",
    "\n",
    "#### Mean Absolute Error (L1 Loss)\n",
    "$\\frac{1}{N}\\sum{|y_i-\\hat{y}_i|}$\n",
    "\n",
    "</br>\n",
    "\n",
    "#### Mean Squared Error (L2 Loss)\n",
    "$\\frac{1}{N}\\sum{(y_i-\\hat{y}_i)}^2$\n",
    "\n",
    "</br>\n",
    "\n",
    "#### Binary Cross Entropy (Log Loss)\n",
    " $L(y, \\hat{y})=\\sum^n_{i=0}-(y\\cdot{log}(p_i)+(1-y_i)\\cdot{log}(1-p_i))$"
   ],
   "id": "41b03b30b6f19c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T22:54:52.065531Z",
     "start_time": "2024-11-21T22:54:52.039877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First we import libraries and build arrays and tensors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.sandbox.stats.ex_newtests import torder\n",
    "\n",
    "# The csv used here can be found at https://github.com/alexcrockett/_analysis_playground/tree/main/Apple%20Stocks/02-data\n",
    "\n",
    "data_file = pd.read_csv('C:/Users/alexa/Documents/Code/Jupyter Playground/Apple Stocks/02-data/AppleStockPrices.csv')\n",
    "data_file_y = data_file['Close']  # Our target values\n",
    "data_file_y_hat_1 = data_file['Open']  # Our first predicted set\n",
    "data_file_y_hat_2 = data_file['High']  # Our second predicted set\n",
    "data_file_y_hat_3 = data_file['Low']  # Our third predicted set\n",
    "data_file_y_hat_4 = data_file['Close']  # Our fourth predicted set\n",
    "\n",
    "# Now we'll convert these to arrays\n",
    "y = data_file_y.to_numpy()\n",
    "hat_1 = data_file_y_hat_1.to_numpy()\n",
    "hat_2 = data_file_y_hat_2.to_numpy()\n",
    "hat_3 = data_file_y_hat_3.to_numpy()\n",
    "hat_4 = data_file_y_hat_4.to_numpy()\n",
    "\n",
    "# Next we'll stack the predicted values into a matrix\n",
    "y_hat = np.stack((hat_1, hat_2, hat_3, hat_4))\n",
    "\n",
    "# Create a tensor from the arrays\n",
    "y_tensor = torch.from_numpy(y).float()\n",
    "y_hat_tensor = torch.from_numpy(y_hat).float()\n",
    "\n",
    "# Check the arrays and tensors\n",
    "print(\"Our target values (numpy): \\n\", y)\n",
    "print(\"\\n\")\n",
    "print(\"Our target values (torch): \\n\", y_tensor)\n",
    "print(\"\\n\")\n",
    "print(\"Our numpy predictions: \\n\", y_hat)\n",
    "print(\"\\n\")\n",
    "print(\"Our numpy predictions (torch): \\n\", y_hat_tensor)"
   ],
   "id": "bf6fd7a8bc8f3eac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our target values (numpy): \n",
      " [329.57 331.29 334.   333.73 336.12 342.45 341.64 344.42 345.68 348.48\n",
      " 340.65 338.84 332.68 326.72 337.45 341.4  343.85 343.21 336.1  339.32\n",
      " 345.03 344.32 343.44 346.5  351.88 355.2  358.16 354.54 356.85 359.18\n",
      " 359.9  363.13 358.3  350.56]\n",
      "\n",
      "\n",
      "Our target values (torch): \n",
      " tensor([329.5700, 331.2900, 334.0000, 333.7300, 336.1200, 342.4500, 341.6400,\n",
      "        344.4200, 345.6800, 348.4800, 340.6500, 338.8400, 332.6800, 326.7200,\n",
      "        337.4500, 341.4000, 343.8500, 343.2100, 336.1000, 339.3200, 345.0300,\n",
      "        344.3200, 343.4400, 346.5000, 351.8800, 355.2000, 358.1600, 354.5400,\n",
      "        356.8500, 359.1800, 359.9000, 363.1300, 358.3000, 350.5600])\n",
      "\n",
      "\n",
      "Our numpy predictions: \n",
      " [[325.64 332.44 329.55 334.72 333.99 338.83 344.88 343.25 345.16 345.89\n",
      "  329.52 348.35 336.43 333.77 326.87 336.33 342.96 343.78 344.17 335.8\n",
      "  341.3  344.45 343.8  343.64 347.89 353.68 355.19 357.39 354.75 356.79\n",
      "  359.19 360.8  357.25 358.71]\n",
      " [330.26 332.5  334.34 335.25 336.35 343.23 344.96 344.43 346.64 348.48\n",
      "  344.76 348.6  338.3  334.88 337.45 341.44 345.6  344.69 344.4  340.04\n",
      "  345.65 345.25 344.24 346.7  353.25 355.52 359.   360.   357.8  359.48\n",
      "  359.97 364.9  360.27 359.5 ]\n",
      " [324.84 328.15 329.5  332.9  331.9  337.17 339.47 342.   343.85 344.44\n",
      "  326.   336.88 330.12 326.63 326.72 334.57 341.5  342.83 333.53 334.3\n",
      "  340.98 343.55 338.55 343.51 347.64 352.15 354.87 348.   353.54 356.71\n",
      "  357.55 360.5  356.52 349.52]\n",
      " [329.57 331.29 334.   333.73 336.12 342.45 341.64 344.42 345.68 348.48\n",
      "  340.65 338.84 332.68 326.72 337.45 341.4  343.85 343.21 336.1  339.32\n",
      "  345.03 344.32 343.44 346.5  351.88 355.2  358.16 354.54 356.85 359.18\n",
      "  359.9  363.13 358.3  350.56]]\n",
      "\n",
      "\n",
      "Our numpy predictions (torch): \n",
      " tensor([[325.6400, 332.4400, 329.5500, 334.7200, 333.9900, 338.8300, 344.8800,\n",
      "         343.2500, 345.1600, 345.8900, 329.5200, 348.3500, 336.4300, 333.7700,\n",
      "         326.8700, 336.3300, 342.9600, 343.7800, 344.1700, 335.8000, 341.3000,\n",
      "         344.4500, 343.8000, 343.6400, 347.8900, 353.6800, 355.1900, 357.3900,\n",
      "         354.7500, 356.7900, 359.1900, 360.8000, 357.2500, 358.7100],\n",
      "        [330.2600, 332.5000, 334.3400, 335.2500, 336.3500, 343.2300, 344.9600,\n",
      "         344.4300, 346.6400, 348.4800, 344.7600, 348.6000, 338.3000, 334.8800,\n",
      "         337.4500, 341.4400, 345.6000, 344.6900, 344.4000, 340.0400, 345.6500,\n",
      "         345.2500, 344.2400, 346.7000, 353.2500, 355.5200, 359.0000, 360.0000,\n",
      "         357.8000, 359.4800, 359.9700, 364.9000, 360.2700, 359.5000],\n",
      "        [324.8400, 328.1500, 329.5000, 332.9000, 331.9000, 337.1700, 339.4700,\n",
      "         342.0000, 343.8500, 344.4400, 326.0000, 336.8800, 330.1200, 326.6300,\n",
      "         326.7200, 334.5700, 341.5000, 342.8300, 333.5300, 334.3000, 340.9800,\n",
      "         343.5500, 338.5500, 343.5100, 347.6400, 352.1500, 354.8700, 348.0000,\n",
      "         353.5400, 356.7100, 357.5500, 360.5000, 356.5200, 349.5200],\n",
      "        [329.5700, 331.2900, 334.0000, 333.7300, 336.1200, 342.4500, 341.6400,\n",
      "         344.4200, 345.6800, 348.4800, 340.6500, 338.8400, 332.6800, 326.7200,\n",
      "         337.4500, 341.4000, 343.8500, 343.2100, 336.1000, 339.3200, 345.0300,\n",
      "         344.3200, 343.4400, 346.5000, 351.8800, 355.2000, 358.1600, 354.5400,\n",
      "         356.8500, 359.1800, 359.9000, 363.1300, 358.3000, 350.5600]])\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T22:54:52.083822Z",
     "start_time": "2024-11-21T22:54:52.077300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now let's compute the L1 loss between our target and predicted values\n",
    "\n",
    "# Using numpy\n",
    "mae_np = np.mean(np.abs(y - y_hat))\n",
    "print(mae_np)"
   ],
   "id": "aba8a8a20c5bab27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3258088235294117\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T22:54:52.127575Z",
     "start_time": "2024-11-21T22:54:52.119704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Using PyTorch\n",
    "\n",
    "# First we need to make sure our tensors are of compatible shapes\n",
    "print(y_tensor.shape)\n",
    "print(y_hat_tensor.shape)\n",
    "\n",
    "\n",
    "# Build a new tensor\n",
    "y_tens_1 = y_tensor\n",
    "y_tens_2 = y_tensor\n",
    "y_tens_3 = y_tensor\n",
    "y_tens_4 = y_tensor\n",
    "y_tens_ = torch.stack((y_tens_1, y_tens_2, y_tens_3, y_tens_4))\n",
    "print(y_tens_.shape)\n",
    "\n",
    "# Now we can compute the L1 Loss\n",
    "mae_torch = torch.nn.L1Loss()\n",
    "mae_torch_computed = mae_torch(y_hat_tensor, y_tens_)\n",
    "print(mae_torch_computed)\n"
   ],
   "id": "c814ed8dfbafd424",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([34])\n",
      "torch.Size([4, 34])\n",
      "torch.Size([4, 34])\n",
      "tensor(2.3258)\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T22:54:52.171212Z",
     "start_time": "2024-11-21T22:54:52.162882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now we can work on the mean squared error (L2)\n",
    "\n",
    "# With numpy\n",
    "mse_np = np.mean((y - y_hat) ** 2)\n",
    "\n",
    "# With PyTorch\n",
    "mse_torch = torch.nn.MSELoss()\n",
    "mse_torch_computed = mse_torch(y_hat_tensor, y_tens_)\n",
    "\n",
    "# Print the results\n",
    "print(mse_np)\n",
    "print(mse_torch_computed)"
   ],
   "id": "bd819d822d8c8af9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.614288970588218\n",
      "tensor(13.6143)\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Recal the binary cross-entropy equation\n",
    "$L(y, \\hat{y})=\\sum^n_{i=0}-(y\\cdot{log}(p_i)+(1-y_i)\\cdot{log}(1-p_i))$"
   ],
   "id": "10c9141ccc724080"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T23:03:48.868975Z",
     "start_time": "2024-11-21T23:03:48.860051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# With numpy\n",
    "\n",
    "# Let's break down the parts of the equation to it's easier to work with\n",
    "epsilon = 1e-15  # Small value to avoid log(0) issues\n",
    "y_hat_ = np.clip(y_hat, epsilon, 1 - epsilon)  # Clipping predicted probabilities to avoid log(0)\n",
    "\n",
    "# Defining the Sigmoid to Compute the function\n",
    "s_pred = 1 / (1 + np.exp(-y_hat_))\n",
    "s_act = 1 / (1 + np.exp(-y))\n",
    "\n",
    "# Calling everything left of the plus sign LHS\n",
    "log_l_np = -np.mean((s_act * np.log(s_pred)) + (1 - s_act) * np.log(1 - s_pred))\n",
    "print(log_l_np)"
   ],
   "id": "8df40e0a0470d4ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3132616875182231\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T23:05:14.092438Z",
     "start_time": "2024-11-21T23:05:14.084278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# With Pytorch\n",
    "log_l_torch_input = torch.nn.Sigmoid()\n",
    "t_hat = log_l_torch_input(y_hat_tensor)\n",
    "t_y = log_l_torch_input(y_tens_)\n",
    "log_l_torch = torch.nn.BCELoss()\n",
    "log_l_torch_compute = log_l_torch(t_hat, t_y)\n",
    "print(log_l_torch_compute)"
   ],
   "id": "ea5929c265a2e286",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c83bc6579e5cbbde"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
